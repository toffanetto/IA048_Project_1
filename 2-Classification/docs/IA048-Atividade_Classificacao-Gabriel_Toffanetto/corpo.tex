%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Apresentação dos dados}

O problema de classificação com o reconhecimento de atividades humanas utiliza como base de dados amostras tomadas do acelerômetro e do giroscópio do \textit{smartphone} preso à cintura do candidato. Dessa forma, com base na leitura desses sensores, pode-se identificar se a pessoa está caminhando, subindo escadas, descendo escadas, sentada, de pé ou deitada, que representam as seis classes do problema.

Além dos dados brutos, é fornecido também os dados processados, com extração sobre os dados no tempo, na frequência, e também características estatísticas dos mesmos.

\subsection{Dados tratados}

Os dados tratados são formados por amostras de 561 atributos derivados da análise no tempo e na frequência dos dados provenientes do acelerômetro e do giroscópio do \textit{smartphone}. São um total de 7352 amostras para treinamento e validação, e 2947 amostras para teste.

O balanceamento das classes nos conjuntos de dados foi realizado por meio do cálculo da taxa de ocorrência dos mesmos, dada de acordo com \eqref{eq:rate}. A \autoref{fig:balancingofclasses} mostra a distribuição das classes, e pode-se ver que não existe um balanceamento homogêneo, onde a classe 3 é a que menos ocorre, enquanto a classe  6 é a que mais ocorre.

Devido a esse desbalanceamento, a métrica que será utilizada para a avaliação do desempenho de cada classificador será a acurácia balanceada, dada por \eqref{eq:ba}.

\begin{equation}\label{eq:rate}
	Rate_i = \frac{N_i}{N}
\end{equation}

% TODO: \usepackage{graphicx} required
\begin{figure}[H]
	\centering
	\includegraphics[width=0.75\linewidth]{../../plot/Balancing_of_classes}
	\caption{Gráfico da ocorrência das classes nos conjuntos de dados de treinamento e teste.}
	\label{fig:balancingofclasses}
\end{figure}

\begin{equation}\label{eq:ba}
	BA = \frac{\sum_{i=1}^{Q}Recall_i}{Q} = \frac{\sum_{i=1}^{Q}\frac{\text{TP}_i}{N_i}}{Q} = \frac{\sum_{i=1}^{Q}\frac{\text{TP}_i}{N\cdot Rate_i}}{Q}
\end{equation}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Classificação via Regressão Logística}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Dados tratados}

\subsubsection{Estrutura de treinamento}





\subsubsection{Passo de evolução}









%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Dados brutos}







%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Classificação via \textit{k neareast neighbours}}

A classificação pelo método \textit{k neareast neighbours} é baseada em inferir a classe do dado a ser classificado com base nos $k$ dados mais próximos à ele. Como hiper-parâmetros para esse problema, têm-se principalmente o valor de $k$, a ordem $p$ da distância de Minkowski entre os dados e o critério de classificação.

O critério de classificação pode se basear puramente na classe majoritária entre os $k$ vizinhos, ou levar em consideração a distância como um peso, que normalmente é inversamente proporcional a distância, evidenciando o rótulo dos pontos mais próximos do dado teste.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Dados tratados}

Para implementação do algoritmo de \textit{k}NN, foi escolhido a utilização da distância euclidiana no espaço dos atributos, e a decisão do rótulo vencedor por meio do voto majoritário dos $k$ vizinhos mais próximos.

Para obtenção do valor de $k$, foi executada uma busca em \textit{grid} do hiper-parâmetro, variando seu valor entre 1 e 29. Utilizando da técnica de validação cruzada \textit{k-fold}, com quatro pastas, foi realizada a inferência das classes dos dados da pasta de validação com base nos vizinhos mais próximos encontrados nas pastas de treinamento, para cada valor de $k$ testado. A \autoref{fig:gridsearch} exibe à evolução da acurácia balanceada para os valores de $k$, obtendo um conjunto de valores ótimos em \eqref{eq:k_fold_k}.

\begin{equation}\label{eq:k_fold_k}
	k = [17\ 28\ 12\ 18]
\end{equation}


% TODO: \usepackage{graphicx} required
\begin{figure}[H]
	\centering
	\includegraphics[width=0.75\linewidth]{../../plot/knn_1/grid_search_k_fold}
	\caption{Busca em \textit{grid} do valor de $k$ ótimo utilizando \textit{4-fold validation}.}
	\label{fig:gridsearch}
\end{figure}

A heurística escolhida para avaliar o melhor valor de $k$ com base no conjunto obtido por meio da busca em \textit{grid} com validação cruzada se dá em obter a acurácia balanceada média das pastas e obter o número de vizinhos que maximiza essa combinação das pastas. A \autoref{fig:gridsearch-k_optimal} mostra a progressão da acurácia balanceada média de acordo com $k$, e assim se obtém o valor de $k$ ótimo em $k = 15$.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.75\linewidth]{../../plot/knn_1/grid_search_k_fold-k_optimal}
	\caption{Busca em \textit{grid} do valor de $k$ ótimo utilizando \textit{4-fold validation}.}
	\label{fig:gridsearch-k_optimal}
\end{figure}



Uma vez definido o classificador ótimo, obtém-se os indicadores de performance do classificador com base nos dados de teste. A acurácia balanceada encontrada foi de 0,8991 e a matriz de confusão do classificador por ser vista na \autoref{tab:mc_knn_1}.

\begin{equation}\label{eq:ba_knn_1}
	BA = 0,8991
\end{equation}

\begin{table}[H]
	\centering
	\begin{tabular}{c||c|c|c|c|c|c|}
		\cline{2-7}
		& \textbf{1} & \textbf{2} & \textbf{3} & \textbf{4} & \textbf{5} & \multicolumn{1}{l|}{\textbf{6}} \\ \hline \hline
		\multicolumn{1}{|c||}{\textbf{1}} & 488 & 0   & 8   & 0   & 0   & 0   \\ \hline
		\multicolumn{1}{|c||}{\textbf{2}} & 39  & 427 & 5   & 0   & 0   & 0   \\ \hline
		\multicolumn{1}{|c||}{\textbf{3}} & 51  & 44  & 325 & 0   & 0   & 0   \\ \hline
		\multicolumn{1}{|c||}{\textbf{4}} & 0   & 4   & 0   & 389 & 98  & 0   \\ \hline
		\multicolumn{1}{|c||}{\textbf{5}} & 0   & 0   & 0   & 31  & 501 & 0   \\ \hline
		\multicolumn{1}{|c||}{\textbf{6}} & 0   & 0   & 0   & 1   & 1   & 535 \\ \hline
	\end{tabular}
	\caption{Matriz de confusão do classificador k-NN com k = 8.}
	\label{tab:mc_knn_1}
\end{table}

Extraindo da matriz de confusão as métricas de precisão e \textit{recall}, obtém-se a \autoref{tab:pr_knn_1}. Pode-se observar que a classe 3 foi a que apresentou menor precisão, sendo muito confundida com a classe 1 e 2. Já a classe 1 possuí o pior \textit{recall}, uma vez que as classes 2 e 3 se confundem com a 1. A classe 6 foi a que apresentou o melhor desempenho, apresentando \textit{recall} unitário, logo, nenhuma classe se confunde com ela, e a maior precisão, muito próxima de 1.


\begin{table}[H]
	\centering
	\begin{tabular}{c|c|c}
		\textbf{Classe} & \textbf{Precisão} & \textbf{\textit{Recall}} \\ \hline
		\textbf{1}      & 0.9839 & 0.8443 \\
		\textbf{2}      & 0.9066 & 0.8989 \\
		\textbf{3}      & 0.7738 & 0.9615 \\
		\textbf{4}      & 0.7923 & 0.9240 \\
		\textbf{5}      & 0.9417 & 0.8350 \\
		\textbf{6}      & 0.9963 & 1.0000
	\end{tabular}
	\caption{Precisão e \textit{Recall} do classificador por classe.}
	\label{tab:pr_knn_1}
\end{table}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Dados brutos}





